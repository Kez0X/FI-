# Les Algorithmes de Tri en Python üî¢

Les algorithmes de tri sont utilis√©s pour organiser les donn√©es de mani√®re efficace. En Python, nous avons plusieurs algorithmes pour trier des donn√©es. Voici une pr√©sentation des **quatre algorithmes de tri principaux** :

1. **Tri par s√©lection** (Selection Sort)
2. **Tri par insertion** (Insertion Sort)
3. **Tri √† bulles** (Bubble Sort)
4. **Tri par fusion** (Merge Sort)

## 1. Tri par S√©lection (Selection Sort) üîΩ

Le **tri par s√©lection** fonctionne en divisant la liste en deux parties :
- Une partie tri√©e √† gauche.
- Une partie non tri√©e √† droite.

L‚Äôalgorithme cherche √† chaque √©tape l'√©l√©ment le plus petit dans la partie non tri√©e et le place √† la fin de la partie tri√©e.

### Description :
1. On parcourt la liste pour trouver l'√©l√©ment le plus petit.
2. On √©change cet √©l√©ment avec le premier √©l√©ment non tri√©.
3. On r√©p√®te cette op√©ration pour les autres √©l√©ments.

### Complexit√© :
- **Temps** : $$\(O(n^2)\)$$ (mauvaise performance pour de grandes listes).
- **Espace** : $$\(O(1)\)$$ (tri en place).

### Code en Python :
```python
def tri_selection(liste):
    n = len(liste)
    for i in range(n):
        # Trouver l'index du minimum dans la partie non tri√©e
        min_index = i
        for j in range(i+1, n):
            if liste[j] < liste[min_index]:
                min_index = j
        # Echanger l'√©l√©ment courant avec l'√©l√©ment le plus petit trouv√©
        liste[i], liste[min_index] = liste[min_index], liste[i]
    return liste

# Exemple d'utilisation
ma_liste = [64, 25, 12, 22, 11]
print(tri_selection(ma_liste))  # [11, 12, 22, 25, 64]
```


## 2. Tri par Insertion (Insertion Sort) ‚¨ÜÔ∏è

Le **tri par insertion** fonctionne de mani√®re similaire √† la fa√ßon dont on trie des cartes √† jouer : on prend un √©l√©ment de la liste et on l'ins√®re dans la partie tri√©e.

### Description :
1. On parcourt la liste √† partir du deuxi√®me √©l√©ment.
2. On ins√®re chaque √©l√©ment √† sa position correcte dans la partie d√©j√† tri√©e.
3. On r√©p√®te l‚Äôop√©ration pour tous les √©l√©ments.

### Complexit√© :
- **Temps** : $$\(O(n^2)\)$$ (mauvaise performance pour de grandes listes).
- **Espace** : $$\(O(1)\)$$ (tri en place).

### Code en Python :
```python
def tri_insertion(liste):
    for i in range(1, len(liste)):
        # L'√©l√©ment √† ins√©rer
        current_value = liste[i]
        j = i - 1
        # D√©caler les √©l√©ments de la partie tri√©e vers la droite
        while j >= 0 and liste[j] > current_value:
            liste[j + 1] = liste[j]
            j -= 1
        # Ins√©rer l'√©l√©ment dans la position correcte
        liste[j + 1] = current_value
    return liste

# Exemple d'utilisation
ma_liste = [64, 25, 12, 22, 11]
print(tri_insertion(ma_liste))  # [11, 12, 22, 25, 64]
```


## 3. Tri √† Bulles (Bubble Sort) üîµ

Le **tri √† bulles** est un algorithme simple mais inefficace qui fonctionne en comparant des √©l√©ments voisins et en les √©changeant si n√©cessaire.

### Description :
1. On compare chaque paire d'√©l√©ments voisins dans la liste.
2. Si l'√©l√©ment de gauche est plus grand que celui de droite, on les √©change.
3. On r√©p√®te ces comparaisons pour chaque √©l√©ment jusqu‚Äô√† ce que la liste soit tri√©e.

### Complexit√© :
- **Temps** : $$\(O(n^2)\)$$ (mauvaise performance pour de grandes listes).
- **Espace** : $$\(O(1)\)$$ (tri en place).

### Code en Python :
```python
def tri_bulles(liste):
    n = len(liste)
    for i in range(n):
        # On suppose que la liste est tri√©e, si aucune permutation n'a lieu
        swapped = False
        for j in range(0, n - i - 1):
            if liste[j] > liste[j + 1]:
                # Echanger les √©l√©ments
                liste[j], liste[j + 1] = liste[j + 1], liste[j]
                swapped = True
        # Si aucune permutation n'a eu lieu, la liste est d√©j√† tri√©e
        if not swapped:
            break
    return liste

# Exemple d'utilisation
ma_liste = [64, 25, 12, 22, 11]
print(tri_bulles(ma_liste))  # [11, 12, 22, 25, 64]
```


## 4. Tri par Fusion (Merge Sort) ‚ö°

Le **tri par fusion** est un algorithme bas√© sur le principe du **diviser pour r√©gner**. Il divise la liste en sous-listes plus petites, les trie r√©cursivement, puis fusionne les sous-listes tri√©es pour obtenir une liste finale tri√©e.

### Description :
1. Diviser la liste en deux sous-listes.
2. Appliquer r√©cursivement le tri √† fusion sur chaque sous-liste.
3. Fusionner les sous-listes tri√©es pour obtenir la liste tri√©e finale.

### Complexit√© :
- **Temps** : $$\(O(n \log n)\)$$ (tr√®s efficace m√™me pour de grandes listes).
- **Espace** : $$\(O(n)\)$$ (n√©cessite de l'espace suppl√©mentaire pour les sous-listes).

### Code en Python :
```python
def fusion(liste1, liste2):
    result = []
    i = j = 0
    # Fusionner les deux listes tri√©es
    while i < len(liste1) and j < len(liste2):
        if liste1[i] < liste2[j]:
            result.append(liste1[i])
            i += 1
        else:
            result.append(liste2[j])
            j += 1
    # Ajouter les √©l√©ments restants
    result.extend(liste1[i:])
    result.extend(liste2[j:])
    return result

def tri_fusion(liste):
    if len(liste) <= 1:
        return liste
    # Diviser la liste en deux
    mid = len(liste) // 2
    left = tri_fusion(liste[:mid])
    right = tri_fusion(liste[mid:])
    # Fusionner les sous-listes tri√©es
    return fusion(left, right)

# Exemple d'utilisation
ma_liste = [64, 25, 12, 22, 11]
print(tri_fusion(ma_liste))  # [11, 12, 22, 25, 64]
```


## R√©sum√© des Algorithmes de Tri

Voici un tableau comparatif des algorithmes de tri mentionn√©s, afin de mieux comprendre leur performance :

| Algorithme        | Complexit√© (Temps)  | Complexit√© (Espace) | Cas moyen/optimal  |
|-------------------|---------------------|---------------------|--------------------|
| Tri √† bulles      | $$\(O(n^2)\)$$          | $$\(O(1)\)$$            | Mauvais            |
| Tri par s√©lection | $$\(O(n^2)\)$$          | $$\(O(1)\)$$            | Mauvais            |
| Tri par insertion | $$\(O(n^2)\)$$          | $$\(O(1)\)$$            | Mauvais            |
| Tri par fusion    | $$\(O(n \log n)\)$$     | $$\(O(n)\)$$            | Tr√®s efficace      |


## Conclusion üéØ

- **Tri √† bulles**, **tri par s√©lection**, et **tri par insertion** sont des algorithmes simples √† comprendre, mais leurs performances sont lentes, surtout pour les grandes listes, avec une complexit√© de $$\(O(n^2)\)$$.
- Le **tri par fusion** est un algorithme beaucoup plus performant avec une complexit√© de $$\(O(n \log n)\)$$, ce qui le rend adapt√© m√™me pour des grandes listes. Cependant, il n√©cessite un espace suppl√©mentaire.

En Python, pour les applications r√©elles, on utilise g√©n√©ralement des fonctions de tri optimis√©es comme **`sorted()`** ou **`sort()`**, qui utilisent un algorithme appel√© **Timsort** et qui est beaucoup plus rapide pour la plupart des cas d'usage. Mais comprendre ces algorithmes est essentiel pour d√©velopper une bonne intuition des performances des algorithmes de tri. üòä

# Les Algorithmes des k Plus Proches Voisins (K-NN) et de Dijkstra üåü

### 1. **L'algorithme des k Plus Proches Voisins (K-NN)** üßë‚Äçüíª

L'algorithme des **k plus proches voisins** (K-NN) est un algorithme de classification et de r√©gression bas√© sur la similarit√© entre les points de donn√©es. Il est largement utilis√© dans le domaine de l'apprentissage supervis√©.

### Description :
- **But** : Classer un point en fonction des k voisins les plus proches dans l'ensemble de donn√©es.
- **Principe** : Pour un point √† classer, l'algorithme cherche les **k points les plus proches** de celui-ci dans l'ensemble d'entra√Ænement et effectue une pr√©diction bas√©e sur la majorit√© des classes de ces voisins.
  
- Si le probl√®me est une **classification**, la classe la plus fr√©quente parmi les k voisins est attribu√©e au point.
- Si c'est une **r√©gression**, la valeur moyenne des k voisins est utilis√©e pour pr√©dire la valeur.

### √âtapes de l'algorithme :
1. Calculer la **distance** entre le point √† classer et tous les autres points de l'ensemble de donn√©es. La distance la plus couramment utilis√©e est la **distance euclidienne**.
2. Identifier les **k voisins les plus proches**.
3. Effectuer la classification ou la r√©gression selon les voisins trouv√©s.

### Exemple de Calcul de Distance Euclidienne :
La distance entre deux points $$ \(A(x_1, y_1)\) $$ et $$ \(B(x_2, y_2)\) $$ dans un plan 2D est donn√©e par :
$$
\[
d(A, B) = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}
\]
$$

### Code en Python :

```python
import numpy as np
from collections import Counter

# Fonction pour calculer la distance euclidienne
def distance(p1, p2):
    return np.sqrt(np.sum((p1 - p2) ** 2))

# Impl√©mentation de l'algorithme K-NN
def knn(X_train, y_train, X_test, k):
    predictions = []
    for test_point in X_test:
        # Calculer la distance de chaque point d'entra√Ænement au point de test
        distances = [distance(test_point, train_point) for train_point in X_train]
        # Trouver les indices des k plus proches voisins
        k_indices = np.argsort(distances)[:k]
        # Obtenir les classes des k plus proches voisins
        k_nearest_labels = [y_train[i] for i in k_indices]
        # La classe la plus fr√©quente devient la pr√©diction
        most_common = Counter(k_nearest_labels).most_common(1)
        predictions.append(most_common[0][0])
    return predictions

# Exemple d'utilisation
X_train = np.array([[1, 2], [2, 3], [3, 4], [5, 6]])
y_train = np.array([0, 0, 1, 1])
X_test = np.array([[2, 2], [4, 5]])

# Appliquer K-NN avec k=3
print(knn(X_train, y_train, X_test, 3))  # R√©sultat : [0, 1]
```

### Complexit√© :
- **Temps** : La recherche des k plus proches voisins n√©cessite de calculer la distance pour chaque point, donc la complexit√© est \(O(n \cdot d)\), o√π \(n\) est le nombre de points et $$\(d\)$$ est la dimension des donn√©es.
- **Espace** : $$\(O(n)\)$$, car il faut stocker les donn√©es d'entra√Ænement.


### 2. **L'Algorithme de Dijkstra** üìç

L'**algorithme de Dijkstra** est un algorithme fondamental en th√©orie des graphes, utilis√© pour **trouver le chemin le plus court** entre un point de d√©part et tous les autres sommets dans un graphe pond√©r√© (avec des poids sur les ar√™tes). C'est un algorithme utilis√© dans de nombreuses applications, comme le calcul d'itin√©raires dans des cartes g√©ographiques ou les r√©seaux.

### Description :
- **But** : Trouver le plus court chemin √† partir d'un sommet source vers tous les autres sommets du graphe, o√π chaque ar√™te a un poids (distance).
- **Principe** : L'algorithme fonctionne en explorant les sommets voisins du sommet actuel et en mettant √† jour les distances minimales trouv√©es. Il utilise une **file de priorit√©** pour toujours explorer le sommet le plus proche (c'est-√†-dire celui ayant la distance minimale).

### √âtapes de l'algorithme :
1. Initialiser la distance de chaque sommet √† l'infini, sauf celle du sommet source qui est initialis√©e √† 0.
2. Placer tous les sommets dans une file de priorit√©.
3. R√©p√©ter :
   - Extraire le sommet avec la distance minimale.
   - Mettre √† jour la distance de ses voisins.
4. L'algorithme se termine lorsque tous les sommets ont √©t√© explor√©s.

### Complexit√© :
- **Temps** : Avec une file de priorit√©, la complexit√© temporelle est $$\(O((V + E) \log V)\)$$, o√π $$\(V\)$$ est le nombre de sommets et $$\(E\)$$ le nombre d'ar√™tes.
- **Espace** : $$\(O(V)\)$$, car on doit stocker les distances et les pr√©d√©cesseurs des sommets.

### Code en Python :

```python
import heapq

def dijkstra(graph, start):
    # Initialisation des distances √† l'infini
    distances = {vertex: float('infinity') for vertex in graph}
    distances[start] = 0
    # File de priorit√© pour explorer les sommets les plus proches
    priority_queue = [(0, start)]
    
    while priority_queue:
        # Extraire le sommet avec la distance minimale
        current_distance, current_vertex = heapq.heappop(priority_queue)
        
        # Si la distance actuelle est d√©j√† plus grande que la distance connue, ignorer
        if current_distance > distances[current_vertex]:
            continue
        
        # Explorer les voisins
        for neighbor, weight in graph[current_vertex].items():
            distance = current_distance + weight
            # Si une distance plus courte est trouv√©e, mettre √† jour
            if distance < distances[neighbor]:
                distances[neighbor] = distance
                heapq.heappush(priority_queue, (distance, neighbor))
    
    return distances

# Exemple d'utilisation
graph = {
    'A': {'B': 1, 'C': 4},
    'B': {'A': 1, 'C': 2, 'D': 5},
    'C': {'A': 4, 'B': 2, 'D': 1},
    'D': {'B': 5, 'C': 1}
}

start_vertex = 'A'
print(dijkstra(graph, start_vertex))
```

### R√©sultat attendu :
```python
{'A': 0, 'B': 1, 'C': 3, 'D': 4}
```

- Le plus court chemin de **A √† B** est de 1, de **A √† C** est de 3, et de **A √† D** est de 4.

### Explication du Code :
1. **graph** : Il s'agit d'un dictionnaire o√π les cl√©s sont les sommets et les valeurs sont les voisins associ√©s avec leurs poids (distances).
2. On initialise les distances des sommets √† l'infini, sauf celle du sommet de d√©part qui est 0.
3. L'algorithme explore les sommets de mani√®re it√©rative en mettant √† jour les distances et en utilisant une file de priorit√© pour toujours explorer le sommet avec la distance la plus courte.


## Conclusion üèÅ

### R√©sum√© des deux algorithmes :

- **K-NN** :
  - Utilis√© pour les probl√®mes de **classification** ou de **r√©gression**.
  - La performance peut √™tre affect√©e par le nombre de points dans l'ensemble d'entra√Ænement.
  - Peut √™tre lent pour de grandes bases de donn√©es sans optimisation.

- **Dijkstra** :
  - Algorithme fondamental pour trouver le **chemin le plus court** dans un graphe pond√©r√©.
  - Tr√®s efficace pour les graphes avec des poids positifs.
  - Utilise une **file de priorit√©** pour explorer les sommets de mani√®re optimale.

Ces deux algorithmes sont tr√®s puissants et largement utilis√©s dans les domaines de l'intelligence artificielle, de la recherche op√©rationnelle, et des applications li√©es aux graphes. üòä